name: CI/CD Pipeline

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

jobs:
  ci-cd:
    runs-on: ubuntu-latest

    steps:
      # 1Ô∏è‚É£ Checkout code
      - name: Checkout code
        uses: actions/checkout@v3

      # 2Ô∏è‚É£ Setup Python
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: 3.11

      # 3Ô∏è‚É£ Install dependencies and Databricks CLI v0.21+
      - name: Install dependencies and configure Databricks CLI
        run: |
          pip install -r requirements.txt
          pip install --upgrade databricks jq
          # Configure CLI using token (new CLI v2.1)
          databricks configure --token <<< "${{ secrets.DATABRICKS_HOST }}\n${{ secrets.DATABRICKS_TOKEN }}"

      # 4Ô∏è‚É£ Run notebooks locally (optional)
      - name: Run pipeline locally with MLflow (Databricks backend)
        env:
          MLFLOW_TRACKING_URI: databricks
          MLFLOW_EXPERIMENT_NAME: /Shared/titanic
          MLFLOW_MODEL_NAME: workspace.my_schema.titanic_model
          MLFLOW_MODEL_STAGE: Staging
          DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
          DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}
        run: |
          python notebooks/01_data_prep.py
          python notebooks/02_train.py
          python notebooks/03_evaluate.py
          python notebooks/04_register_model.py

      # 5Ô∏è‚É£ Create or update Databricks Job (new CLI v2.1 compatible)
      - name: Deploy Databricks Job
        env:
          DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
          DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}
        run: |
          echo "üîπ Fetching existing jobs..."
          JOB_ID=$(databricks jobs list --output JSON | jq -r '.jobs[]? | select(.settings.name=="titanic_pipeline") | .job_id')
          
          if [ -n "$JOB_ID" ]; then
            echo "‚ÑπÔ∏è Updating existing job $JOB_ID"
            databricks jobs reset --job-id "$JOB_ID" --json-file jobs/titanic_job.yaml
          else
            echo "‚ÑπÔ∏è Creating new job"
            databricks jobs create --json-file jobs/titanic_job.yaml
          fi

      # 6Ô∏è‚É£ Trigger Databricks Job and wait for completion
      - name: Run Databricks Job
        env:
          DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
          DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}
        run: |
          JOB_ID=$(databricks jobs list --output JSON | jq -r '.jobs[]? | select(.settings.name=="titanic_pipeline") | .job_id')
          if [ -z "$JOB_ID" ]; then
            echo "‚ùå Job not found!"
            exit 1
          fi

          echo "‚ñ∂Ô∏è Triggering job: $JOB_ID"
          RUN_JSON=$(databricks jobs run-now --job-id "$JOB_ID" --output JSON)
          RUN_ID=$(echo "$RUN_JSON" | jq -r '.run_id')
          echo "‚è≥ Waiting for run $RUN_ID to finish..."
          databricks runs wait --run-id "$RUN_ID"

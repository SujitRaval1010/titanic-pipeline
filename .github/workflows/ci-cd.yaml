name: CI/CD Pipeline

on:
  push:
    branches:
      - main
  pull_request:
    branches:
      - main

jobs:
  ci-cd:
    runs-on: ubuntu-latest
    steps:
      # 1️⃣ Checkout repo
      - name: Checkout code
        uses: actions/checkout@v3

      # 2️⃣ Setup Python
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: 3.11

      # 3️⃣ Install dependencies
      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          pip install databricks-cli==0.18.0  # Correct version

      # 4️⃣ Optional: run Python scripts locally to test
      - name: Run local scripts
        run: |
          python notebooks/01_data_prep.py
          python notebooks/02_train.py
          python notebooks/03_evaluate.py
          python notebooks/04_register_model.py

      # 5️⃣ Deploy Databricks Job (using YAML)
      - name: Deploy Databricks Job
        run: |
          databricks jobs create --json-file jobs/titanic_job.yaml || echo "Job already exists"
        env:
          DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
          DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}

      # 6️⃣ Trigger Databricks Job Run
      - name: Run Databricks Job
        run: |
          JOB_ID=$(databricks jobs list | grep titanic_pipeline | awk '{print $1}')
          databricks jobs run-now --job-id $JOB_ID
        env:
          DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
          DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}

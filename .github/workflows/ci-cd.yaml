name: CI/CD Pipeline

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

jobs:
  ci-cd:
    runs-on: ubuntu-latest

    steps:
      # 1️⃣ Checkout repo
      - name: Checkout code
        uses: actions/checkout@v3

      # 2️⃣ Setup Python
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: 3.11

      # 3️⃣ Install dependencies
      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          pip install databricks-cli==0.18.0 jq

      # 4️⃣ Run scripts locally (optional) - logs to Databricks MLflow
      - name: Run pipeline locally with MLflow (Databricks backend)
        env:
          MLFLOW_TRACKING_URI: databricks
          MLFLOW_EXPERIMENT_NAME: /Shared/titanic
          MLFLOW_MODEL_NAME: workspace.my_schema.titanic_model   # ✅ UC model path
          MLFLOW_MODEL_STAGE: Staging                           # ✅ Stage for promotion
          DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
          DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}
        run: |
          python notebooks/01_data_prep.py
          python notebooks/02_train.py
          python notebooks/03_evaluate.py
          python notebooks/04_register_model.py

      # 5️⃣ Create or update Databricks Job
      - name: Deploy Databricks Job
        env:
          DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
          DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}
        run: |
          JOB_ID=$(databricks jobs list --output JSON | jq -r '.jobs[] | select(.settings.name=="titanic_pipeline") | .job_id')
          if [ -n "$JOB_ID" ]; then
            echo "ℹ️ Updating existing job $JOB_ID"
            databricks jobs reset --job-id "$JOB_ID" --json-file jobs/titanic_job.yaml
          else
            echo "ℹ️ Creating new job"
            databricks jobs create --json-file jobs/titanic_job.yaml
          fi

      # 6️⃣ Trigger Databricks Job and wait for completion
      - name: Run Databricks Job
        env:
          DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
          DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}
        run: |
          JOB_ID=$(databricks jobs list --output JSON | jq -r '.jobs[] | select(.settings.name=="titanic_pipeline") | .job_id')
          echo "▶️ Triggering job: $JOB_ID"
          RUN_JSON=$(databricks jobs run-now --job-id "$JOB_ID" --output JSON)
          RUN_ID=$(echo "$RUN_JSON" | jq -r '.run_id')
          echo "Waiting for run $RUN_ID to finish..."
          databricks runs wait --run-id "$RUN_ID"

name: CI/CD Pipeline

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

jobs:
  ci-cd:
    runs-on: ubuntu-latest

    steps:
      # 1Ô∏è‚É£ Checkout code
      - name: Checkout code
        uses: actions/checkout@v3

      # 2Ô∏è‚É£ Setup Python
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: 3.11

      # 3Ô∏è‚É£ Install dependencies + Databricks CLI (v0.21+)
      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          pip install --upgrade databricks jq

      # 4Ô∏è‚É£ (Optional) Run notebooks locally with MLflow backend
      - name: Run pipeline locally (optional)
        if: github.event_name == 'pull_request'
        env:
          MLFLOW_TRACKING_URI: databricks
          MLFLOW_EXPERIMENT_NAME: /Shared/titanic
          MLFLOW_MODEL_NAME: workspace.my_schema.titanic_model
          MLFLOW_MODEL_STAGE: Staging
          DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
          DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}
        run: |
          python notebooks/01_data_prep.py
          python notebooks/02_train.py
          python notebooks/03_evaluate.py
          python notebooks/04_register_model.py

      # 5Ô∏è‚É£ Deploy or update Databricks Job
      - name: Deploy Databricks Job
        env:
          DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
          DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}
        run: |
          echo "üîπ Checking if job already exists..."
          JOB_ID=$(databricks jobs list --output JSON | jq -r '.jobs[]? | select(.settings.name=="titanic_pipeline") | .job_id')

          if [ -n "$JOB_ID" ]; then
            echo "‚ÑπÔ∏è Updating existing job $JOB_ID"
            databricks jobs reset --job-id "$JOB_ID" --json-file jobs/titanic_job.yaml
          else
            echo "‚ÑπÔ∏è Creating new job"
            databricks jobs create --json-file jobs/titanic_job.yaml
          fi

      # 6Ô∏è‚É£ Trigger Databricks Job and wait for completion
      - name: Run Databricks Job
        env:
          DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
          DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}
        run: |
          JOB_ID=$(databricks jobs list --output JSON | jq -r '.jobs[]? | select(.settings.name=="titanic_pipeline") | .job_id')
          if [ -z "$JOB_ID" ]; then
            echo "‚ùå Job not found!"
            exit 1
          fi

          echo "‚ñ∂Ô∏è Triggering job: $JOB_ID"
          RUN_JSON=$(databricks jobs run-now --job-id "$JOB_ID" --output JSON)
          RUN_ID=$(echo "$RUN_JSON" | jq -r '.run_id')
          echo "‚è≥ Waiting for run $RUN_ID to finish..."
          databricks runs wait --run-id "$RUN_ID"

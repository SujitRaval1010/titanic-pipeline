name: Databricks CI/CD Pipeline

on:
  push:
    branches:
      - main

jobs:
  deploy-to-databricks:
    runs-on: ubuntu-latest

    steps:
      # Step 1: Checkout repo
      - name: Checkout repository
        uses: actions/checkout@v3

      # Step 2: Install Databricks CLI
      - name: Install Databricks CLI
        run: pip install databricks-cli jq

      # Step 3: Set Databricks environment variables (non-interactive auth)
      - name: Configure Databricks environment
        run: |
          echo "DATABRICKS_HOST=${{ secrets.DATABRICKS_HOST }}" >> $GITHUB_ENV
          echo "DATABRICKS_TOKEN=${{ secrets.DATABRICKS_TOKEN }}" >> $GITHUB_ENV

      # Step 4: Check if job exists
      - name: Check if job exists
        id: check_job
        run: |
          if databricks jobs list --output JSON | jq -e '.jobs[] | select(.settings.name=="mlops-job")' > /dev/null; then
            echo "exists=true" >> $GITHUB_ENV
          else
            echo "exists=false" >> $GITHUB_ENV
          fi

      # Step 5: Create job if not exists
      - name: Create Databricks Job
        if: env.exists == 'false'
        run: |
          databricks jobs create --json '{
            "name": "mlops-job",
            "tasks": [
              {
                "task_key": "train_and_register",
                "notebook_task": {
                  "notebook_path": "/Repos/your-repo-path/train_model"
                },
                "existing_cluster_id": "your-cluster-id"
              }
            ]
          }'

      # Step 6: Trigger job run
      - name: Run Databricks Job
        run: |
          JOB_ID=$(databricks jobs list --output JSON | jq -r '.jobs[] | select(.settings.name=="mlops-job").job_id')
          databricks jobs run-now --job-id $JOB_ID
